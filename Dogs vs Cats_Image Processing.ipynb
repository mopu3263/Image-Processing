{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\nThis example shows how to do image classification from scratch, starting from JPEG image files on disk, without leveraging pre-trained weights or a pre-made Keras Application model. We demonstrate the workflow on the Kaggle Cats vs Dogs binary classification dataset.\n\nI use the image_dataset_from_directory utility to generate the datasets, and we use Keras image preprocessing layers for image standardization and data augmentation. "},{"metadata":{},"cell_type":"markdown","source":"# Setup"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generate Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_size = (180, 180)\nbatch_size = 32\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    '../input/cat-and-dog/training_set/training_set',\n    validation_split=0.2,\n    subset=\"training\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n)\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    '../input/cat-and-dog/training_set/training_set',\n    validation_split=0.2,\n    subset=\"validation\",\n    seed=1337,\n    image_size=image_size,\n    batch_size=batch_size,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Visualize the data\nHere are the first 9 images in the training dataset. As you can see, label 1 is \"dog\" and label 0 is \"cat\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"# Using image data augmentation\nWhen you don't have a large image dataset, it's a good practice to artificially introduce sample diversity by applying random yet realistic transformations to the training images, such as random horizontal flipping or small random rotations. This helps expose the model to different aspects of the training data while slowing down overfitting."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        layers.experimental.preprocessing.RandomRotation(0.1),\n    ]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's visualize what the augmented samples look like, by applying data_augmentation repeatedly to the first image in the dataset:"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Two options to preprocess the data\nOption 1: Make it part of the model: With this option, your data augmentation will happen on device, synchronously with the rest of the model execution, meaning that it will benefit from GPU acceleration. Note that data augmentation is inactive at test time, so the input samples will only be augmented during fit(), not when calling evaluate() or predict().If you're training on GPU, this is the better option.\n\nOption 2: apply it to the dataset, so as to obtain a dataset that yields batches of augmented images.With this option, your data augmentation will happen on CPU, asynchronously, and will be buffered before going into the model. If you're training on CPU, this is the better option, since it makes data augmentation asynchronous and non-blocking.\n\nIn our case, we'll go with the first option.\n"},{"metadata":{},"cell_type":"markdown","source":"# Configure the dataset for performance\nLet's make sure to use buffered prefetching so we can yield data from disk without having I/O becoming blocking:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_ds = train_ds.prefetch(buffer_size=32)\nval_ds = val_ds.prefetch(buffer_size=32)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build a model\n\nNote that:\nWe start the model with the data_augmentation preprocessor, followed by a Rescaling layer.\nWe include a Dropout layer before the final classification layer."},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef make_model(input_shape, num_classes):\n    inputs=keras.Input(shape=input_shape)\n    #Image augmentation block\n    x = data_augmentation(inputs)\n    \n    #Entry block\n    x = layers.experimental.preprocessing.Rescaling(1./255)(x)\n    x=layers.Conv2D(32,3,strides=2,padding=\"same\")(x)\n    x=layers.BatchNormalization()(x)\n    x=layers.Activation(\"relu\")(x)\n    \n\n    x=layers.Conv2D(64,3,padding=\"same\")(x)\n    x=layers.BatchNormalization()(x)\n    x=layers.Activation(\"relu\")(x)\n    \n    previous_block_activation = x  # Set aside residual\n    \n    for size in [128, 256, 512, 728]:\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.Activation(\"relu\")(x)\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        x = layers.BatchNormalization()(x)\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n\n        # Project residual\n        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        x = layers.add([x, residual])  # Add back residual\n        previous_block_activation = x  # Set aside next residual\n        \n    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation(\"relu\")(x)\n    \n    x = layers.GlobalAveragePooling2D()(x)\n    \n    if num_classes==2:\n        activation=\"sigmoid\"\n        units=1\n        \n    else:\n        activation=\"softmax\"\n        units=num_classes\n        \n    x=layers.Dropout(0.5)(x)\n    outputs=layers.Dense(units,activation=activation)(x)\n    return keras.Model(inputs,outputs)\n\nmodel=make_model(input_shape=image_size+(3,),num_classes=2)\nkeras.utils.plot_model(model,show_shapes=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 50\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n]\nmodel.compile(\n    optimizer=keras.optimizers.Adam(1e-3),\n    loss=\"binary_crossentropy\",\n    metrics=[\"accuracy\"],\n)\nmodel.fit(\n    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Run inference on new data\nNote that data augmentation and dropout are inactive at inference time\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"img = keras.preprocessing.image.load_img(\n    '../input/cat-and-dog/training_set/training_set/dogs/dog.1006.jpg', target_size=image_size\n)\nimg_array = keras.preprocessing.image.img_to_array(img)\nimg_array = tf.expand_dims(img_array, 0)  # Create batch axis\n\npredictions = model.predict(img_array)\nscore = predictions[0]\nprint(\n    \"This image is %.2f percent cat and %.2f percent dog.\"\n    % (100 * (1 - score), 100 * score)\n)\nif predictions[0][0] >=0.5:\n    prediction='dog'\nelse:\n    prediction='cat'\nprint(prediction)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}